{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bittensorflowvenvc5ae079d33a94b2797c1e2237094a841",
   "display_name": "Python 3.8.5 64-bit ('tensorflow': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ownlabelme2COCO  \n",
    "\n",
    "In diesem Notebook wird der Code erklärt, der die Informationen in den einzelnen, durch die Software \"Labelme\" erzeugten, json-Dateien zu einer COCO-konformen json-Datei umstrukturiert.  \n",
    "Inspiration für dieses Programm lieferte der [Blog-Post](https://www.dlology.com/blog/how-to-create-custom-coco-data-set-for-instance-segmentation/) vom GitHub-User Tony607. Sein Programm stellte sich jedoch als unkompatibel mit den erzeugten json-Dateien heraus, weswegen der folgende Code geschrieben wurde.  \n",
    "Im Unterschied zu Tony607 wurde ein Objekt orientierter Ansatz gewählt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Die COCO-konformen Dateien für detectron2 setzen sich aus drei objektkategorien zusammen - Bilder, Kategorien und Annotationen. Für jede dieser Bezeichnungen wird zunächst eine Klasse erstellt.  \n",
    "Alle Klassen setzen sich aus drei Funktionen zusammen. Der Konstruktor _init_ setzt die Klassenattribute, die _print_-Funktion gibt einen formatierten String mit allen Klassenattributen aus und die _convertToDictionary_ Funktion gibt ein Dictionary zurück, welches zum Export der Daten in die Zieldatei dient.  \n",
    "Die Klassen unterscheiden sich in ihren Klassenattributen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "\n",
    "    __doc__ = \"The class, representing the image Data for the COCO Dataset\"\n",
    "\n",
    "    def __init__(self, id, name, height, width):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def print(self):\n",
    "        return '\"height\": {}\\n,\"width\": {}\\n,\"id\": {}\\n,\"file_name\": {}\\n'.format(\n",
    "            self.height,\n",
    "            self.width,\n",
    "            self.id,\n",
    "            self.name)\n",
    "\n",
    "    def convertToDictionary(self):\n",
    "        imagedict = {}\n",
    "        imagedict[\"height\"] = self.height\n",
    "        imagedict[\"width\"] = self.width\n",
    "        imagedict[\"id\"] = self.id\n",
    "        imagedict[\"file_name\"] = self.name\n",
    "\n",
    "        return imagedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "\n",
    "    __doc__ = \"The class, representing the categorie Data for the COCO Dataset\"\n",
    "\n",
    "    def __init__(self, id, supercategory, name):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.supercategory = supercategory\n",
    "\n",
    "    def print(self):\n",
    "        return '\"Supercategory: {}\\n\"id\": {}\\n\"category\": {}\\n'.format(\n",
    "            self.supercategory,\n",
    "            self.id,\n",
    "            self.name)\n",
    "    \n",
    "    def convertToDictionary(self):\n",
    "        categorydict = {}\n",
    "        categorydict[\"supercategory\"] = self.supercategory\n",
    "        categorydict[\"id\"] = self.id\n",
    "        categorydict[\"name\"] = self.name\n",
    "\n",
    "        return categorydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polygon:\n",
    "    \n",
    "    __doc__ = \"The class, representing the categorie Data for the COCO Dataset\"\n",
    "\n",
    "    def __init__(self, id, category_id, image_id, iscrowd, segmentation, bbox, area):\n",
    "        self.id = id\n",
    "        self.category_id = category_id\n",
    "        self.image_id = image_id\n",
    "        self.iscrowd = iscrowd\n",
    "        self.segmentation = segmentation\n",
    "        self.bbox = bbox\n",
    "        self.area = area\n",
    "\n",
    "    def print(self):\n",
    "        return '\"segmentation\": {}\\n\"iscrowd\": {}\\n\"area\": {}\\n\"image_id\": {}\\n\"bbox\": {}\\n\"category_id\": {}\\n\"id\": {}\\n'.format(\n",
    "            self.segmentation,\n",
    "            self.iscrowd,\n",
    "            self.area,\n",
    "            self.image_id,\n",
    "            self.bbox,\n",
    "            self.category_id,\n",
    "            self.id)\n",
    "\n",
    "    def convertToDictionary(self):\n",
    "        polygondict = {}\n",
    "        polygondict[\"segmentation\"] = self.segmentation\n",
    "        polygondict[\"iscrowd\"] = self.iscrowd\n",
    "        polygondict[\"area\"] = self.area\n",
    "        polygondict[\"image_id\"] = self.image_id\n",
    "        polygondict[\"bbox\"] = self.bbox\n",
    "        polygondict[\"category_id\"] = self.category_id\n",
    "        polygondict[\"id\"] = self.id\n",
    "\n",
    "        return polygondict"
   ]
  },
  {
   "source": [
    "Die Funktion zur Errechnung der Poligonfläche wurde diesem [Stackoverflow Posting](https://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates) entnommen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyArea(x, y):\n",
    "    return 0.5*np.abs(np.dot(x, np.roll(y, 1))-np.dot(y, np.roll(x, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"/home/julius/PowerFolders/Masterarbeit/\"\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "DATASET_PATH = \"./1_Datensaetze/first_annotation_dataset/\"\n",
    "\n",
    "json_dump = {}\n",
    "images = []\n",
    "categories = []\n",
    "polygons = []\n",
    "label_list = {}\n",
    "polygon_list = []\n",
    "\n",
    "# get all json files in directory\n",
    "json_list = sorted([f for f in os.listdir(DATASET_PATH) if f.endswith(\".json\")])"
   ]
  },
  {
   "source": [
    "Das eigentliche Programm sammelt nach der Definition der Variablen alle .json Dateien im angegebenen Ordner in einer sortierten Liste.  \n",
    "Danach wird über jede Datei in dieser Liste in mehreren for-Schleifen iteriert.  \n",
    "In der ersten for-Schleife werden die nötigen Informationen für die _Image_ Klasse aus der Datei gezogen. In der zweiten Schleife dann die _Category_ Daten und abschließend die Koordinaten des Polygons. Innerhalb der zweiten for schleife werden die getrennten X und Y Koordinaten mit einander verzahnt, die _Bounding Box_ und der Flächeninhalt des Vielecks ermittelt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_count, json_file in enumerate(json_list):\n",
    "    with open(DATASET_PATH + json_file, \"r\") as content:\n",
    "        data = json.load(content)\n",
    "        \n",
    "        image = Image(id_count, data[\"imagePath\"].replace(\"../\", \"\"), data[\"imageHeight\"], data[\"imageWidth\"])\n",
    "        image_as_dict = image.convertToDictionary()\n",
    "        images.append(image_as_dict)\n",
    "\n",
    "        for shape_count, element in enumerate(data[\"shapes\"]):\n",
    "            if element[\"label\"] not in label_list:\n",
    "                category = Category((len(label_list)), None, element[\"label\"])\n",
    "                category_as_dict = category.convertToDictionary()\n",
    "                categories.append(category_as_dict)\n",
    "                label_list[element[\"label\"]] = (len(label_list))\n",
    "\n",
    "            x_coordinates = []\n",
    "            y_coordinates = []\n",
    "\n",
    "            # extract the polgon points\n",
    "            for polygon in element[\"points\"]:\n",
    "                x_coordinates.append(polygon[0])\n",
    "                y_coordinates.append(polygon[1])\n",
    "\n",
    "            # transform into COCO format\n",
    "            segmentation = []\n",
    "            segmentation.append(list(sum(zip(x_coordinates, y_coordinates), ())))\n",
    "\n",
    "            # get the values of the bbox\n",
    "            smallest_x = int(min(x_coordinates))\n",
    "            smallest_y = int(min(y_coordinates))\n",
    "            biggest_x = int(max(x_coordinates))\n",
    "            biggest_y = int(max(y_coordinates))\n",
    "\n",
    "            bbox_height = biggest_y-smallest_y\n",
    "            bbox_width = biggest_x-smallest_x\n",
    "\n",
    "            bbox = [smallest_x, smallest_y, bbox_width, bbox_height]\n",
    "\n",
    "            # get the area of the polygon\n",
    "            polygon_area = PolyArea(x_coordinates, y_coordinates)\n",
    "\n",
    "            # create polygon instance and add it to the list\n",
    "            polygon = Polygon(len(polygon_list), label_list[element[\"label\"]], id_count, 0, segmentation, bbox, polygon_area)\n",
    "            polygon_as_dict = polygon.convertToDictionary()\n",
    "            polygons.append(polygon_as_dict)\n",
    "            polygon_list.append(shape_count)"
   ]
  },
  {
   "source": [
    "Nach dem Auslesen und Sortieren der Daten werden diese in das Dictionary eingefügt, das auch die json Struktur der endgültigen Datei wiederspiegeln soll. Dieses wird am Ende in ein entsprechendes Unterverzeichnis im Datensatz eingefügt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dump[\"images\"] = images\n",
    "json_dump[\"categories\"] = categories\n",
    "json_dump[\"annotations\"] = polygons\n",
    "\n",
    "output_path = DATASET_PATH + \"COCO_json\"\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "with open(output_path + \"/output.json\", \"w\") as output_file:\n",
    "    json.dump(json_dump, output_file, indent=4)"
   ]
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import load_coco_json, register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random, cv2, time, os, shutil, ownlabelme2COCO, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "source": [
    "Definition des Hauptpfads, der Input-Pfade und der Output-Pfade"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/home/julius/PowerFolders/Masterarbeit/\"\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./1_Datensaetze/personData200/\"\n",
    "train_set_path = dataset_path + \"train_split/\"\n",
    "test_set_path = dataset_path + \"test_split/\"\n",
    "\n",
    "starttime = time.strftime(\"%d,%m,%Y-%H,%M\")\n",
    "model_path = work_dir + \"trained_models/detectron2/{}/{}/\".format(dataset_path.split(\"/\")[-2], starttime)"
   ]
  },
  {
   "source": [
    "Erstellen des Datensplits, wenn dies noch nicht vorliegt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uneven_list_error(Exception):\n",
    "    # raised, when the two lists which are needed to seperate the data are uneven.\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if not os.path.isdir(train_set_path) & os.path.isdir(test_set_path):\n",
    "        os.mkdir(train_set_path)\n",
    "        os.mkdir(test_set_path)\n",
    "    \n",
    "        images = sorted([element for element in os.listdir(dataset_path) if element.lower().endswith(\".jpg\")])\n",
    "        jsons = sorted([element for element in os.listdir(dataset_path) if element.endswith(\".json\")])\n",
    "\n",
    "        if len(images) != len(jsons):\n",
    "            raise uneven_list_error\n",
    "\n",
    "        for count in range(len(images)):\n",
    "            if count % 5 == 0:\n",
    "                shutil.move(dataset_path + images[count], test_set_path + images[count])\n",
    "                shutil.move(dataset_path + jsons[count], test_set_path + jsons[count])\n",
    "            else:\n",
    "                shutil.move(dataset_path + images[count], train_set_path + images[count])\n",
    "                shutil.move(dataset_path + jsons[count], train_set_path + jsons[count])\n",
    "        \n",
    "        ownlabelme2COCO.main(test_set_path)\n",
    "        ownlabelme2COCO.main(train_set_path)\n",
    "\n",
    "except uneven_list_error:\n",
    "    print(\"[ERROR] List lengths don't match! There are {} Images and {} json-Files. Please check directory!\".format(len(images), len(jsons)))\n",
    "    break"
   ]
  },
  {
   "source": [
    "Einlesen der beiden Datens√§tze"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_coco_json(train_set_path + \"COCO_json/output.json\", train_set_path, \"train_set\")\n",
    "register_coco_instances(\"train_set\", {}, train_set_path + \"COCO_json/output.json\", train_set_path)\n",
    "train_set_metadata = MetadataCatalog.get(\"train_set\")\n",
    "train_set_data = DatasetCatalog.get(\"train_set\")\n",
    "\n",
    "load_coco_json(test_set_path + \"COCO_json/output.json\", test_set_path, \"test_set\")\n",
    "register_coco_instances(\"test_set\", {}, test_set_path + \"COCO_json/output.json\", test_set_path)\n",
    "test_set_metadata = MetadataCatalog.get(\"test_set\")\n",
    "test_set_data = DatasetCatalog.get(\"test_set\")"
   ]
  },
  {
   "source": [
    "probeweises Anschauen des gelesenen Datensatzes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image = random.sample(train_set_data, 1)[0]\n",
    "image = cv2.imread(random_image[\"file_name\"])\n",
    "visualizer = Visualizer(image, metadata=train_set_metadata, scale=1, instance_mode=ColorMode.SEGMENTATION)\n",
    "visualization = visualizer.draw_dataset_dict(random_image)\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.imshow(visualization.get_image()[:,:, ::-1])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nconfig.DATASETS.TRAIN = (\"train_set\",)\\nconfig.DATASETS.TEST = (\"test_set\",)\\nconfig.DATALOADER.NUM_WORKERS = 2\\nconfig.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\\nconfig.OUTPUT_DIR = model_path\\nconfig.SOLVER.IMS_PER_BATCH = 2\\nconfig.SOLVER.REFERENCE_WORLD_SIZE = 1\\nconfig.SOLVER.BASE_LR = 0.02\\nconfig.SOLVER.MAX_ITER = 150\\nconfig.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\\nconfig.MODEL.ROI_HEADS.NUM_CLASSES = 16\\nconfig.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "config = get_cfg()\n",
    "config.merge_from_file(\"/home/julius/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\"\"\"\n",
    "config.DATASETS.TRAIN = (\"train_set\",)\n",
    "config.DATASETS.TEST = (\"test_set\",)\n",
    "config.DATALOADER.NUM_WORKERS = 2\n",
    "config.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
    "config.OUTPUT_DIR = model_path\n",
    "config.SOLVER.IMS_PER_BATCH = 2\n",
    "config.SOLVER.REFERENCE_WORLD_SIZE = 1\n",
    "config.SOLVER.BASE_LR = 0.02\n",
    "config.SOLVER.MAX_ITER = 150\n",
    "config.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\n",
    "config.MODEL.ROI_HEADS.NUM_CLASSES = 16\n",
    "config.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CUDNN_BENCHMARK: False\nDATALOADER:\n  ASPECT_RATIO_GROUPING: True\n  FILTER_EMPTY_ANNOTATIONS: True\n  NUM_WORKERS: 4\n  REPEAT_THRESHOLD: 0.0\n  SAMPLER_TRAIN: TrainingSampler\nDATASETS:\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n  PROPOSAL_FILES_TEST: ()\n  PROPOSAL_FILES_TRAIN: ()\n  TEST: ('coco_2017_val',)\n  TRAIN: ('coco_2017_train',)\nGLOBAL:\n  HACK: 1.0\nINPUT:\n  CROP:\n    ENABLED: False\n    SIZE: [0.9, 0.9]\n    TYPE: relative_range\n  FORMAT: BGR\n  MASK_FORMAT: polygon\n  MAX_SIZE_TEST: 1333\n  MAX_SIZE_TRAIN: 1333\n  MIN_SIZE_TEST: 800\n  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n  MIN_SIZE_TRAIN_SAMPLING: choice\n  RANDOM_FLIP: horizontal\nMODEL:\n  ANCHOR_GENERATOR:\n    ANGLES: [[-90, 0, 90]]\n    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n    NAME: DefaultAnchorGenerator\n    OFFSET: 0.0\n    SIZES: [[32], [64], [128], [256], [512]]\n  BACKBONE:\n    FREEZE_AT: 2\n    NAME: build_resnet_fpn_backbone\n  DEVICE: cuda\n  FPN:\n    FUSE_TYPE: sum\n    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n    NORM: \n    OUT_CHANNELS: 256\n  KEYPOINT_ON: False\n  LOAD_PROPOSALS: False\n  MASK_ON: True\n  META_ARCHITECTURE: GeneralizedRCNN\n  PANOPTIC_FPN:\n    COMBINE:\n      ENABLED: True\n      INSTANCES_CONFIDENCE_THRESH: 0.5\n      OVERLAP_THRESH: 0.5\n      STUFF_AREA_LIMIT: 4096\n    INSTANCE_LOSS_WEIGHT: 1.0\n  PIXEL_MEAN: [103.53, 116.28, 123.675]\n  PIXEL_STD: [1.0, 1.0, 1.0]\n  PROPOSAL_GENERATOR:\n    MIN_SIZE: 0\n    NAME: RPN\n  RESNETS:\n    DEFORM_MODULATED: False\n    DEFORM_NUM_GROUPS: 1\n    DEFORM_ON_PER_STAGE: [False, False, False, False]\n    DEPTH: 50\n    NORM: FrozenBN\n    NUM_GROUPS: 1\n    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n    RES2_OUT_CHANNELS: 256\n    RES5_DILATION: 1\n    STEM_OUT_CHANNELS: 64\n    STRIDE_IN_1X1: True\n    WIDTH_PER_GROUP: 64\n  RETINANET:\n    BBOX_REG_LOSS_TYPE: smooth_l1\n    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n    FOCAL_LOSS_ALPHA: 0.25\n    FOCAL_LOSS_GAMMA: 2.0\n    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n    IOU_LABELS: [0, -1, 1]\n    IOU_THRESHOLDS: [0.4, 0.5]\n    NMS_THRESH_TEST: 0.5\n    NORM: \n    NUM_CLASSES: 80\n    NUM_CONVS: 4\n    PRIOR_PROB: 0.01\n    SCORE_THRESH_TEST: 0.05\n    SMOOTH_L1_LOSS_BETA: 0.1\n    TOPK_CANDIDATES_TEST: 1000\n  ROI_BOX_CASCADE_HEAD:\n    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n    IOUS: (0.5, 0.6, 0.7)\n  ROI_BOX_HEAD:\n    BBOX_REG_LOSS_TYPE: smooth_l1\n    BBOX_REG_LOSS_WEIGHT: 1.0\n    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n    CLS_AGNOSTIC_BBOX_REG: False\n    CONV_DIM: 256\n    FC_DIM: 1024\n    NAME: FastRCNNConvFCHead\n    NORM: \n    NUM_CONV: 0\n    NUM_FC: 2\n    POOLER_RESOLUTION: 7\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n    SMOOTH_L1_BETA: 0.0\n    TRAIN_ON_PRED_BOXES: False\n  ROI_HEADS:\n    BATCH_SIZE_PER_IMAGE: 512\n    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n    IOU_LABELS: [0, 1]\n    IOU_THRESHOLDS: [0.5]\n    NAME: StandardROIHeads\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 80\n    POSITIVE_FRACTION: 0.25\n    PROPOSAL_APPEND_GT: True\n    SCORE_THRESH_TEST: 0.05\n  ROI_KEYPOINT_HEAD:\n    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n    LOSS_WEIGHT: 1.0\n    MIN_KEYPOINTS_PER_IMAGE: 1\n    NAME: KRCNNConvDeconvUpsampleHead\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n    NUM_KEYPOINTS: 17\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  ROI_MASK_HEAD:\n    CLS_AGNOSTIC_MASK: False\n    CONV_DIM: 256\n    NAME: MaskRCNNConvUpsampleHead\n    NORM: \n    NUM_CONV: 4\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  RPN:\n    BATCH_SIZE_PER_IMAGE: 256\n    BBOX_REG_LOSS_TYPE: smooth_l1\n    BBOX_REG_LOSS_WEIGHT: 1.0\n    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n    BOUNDARY_THRESH: -1\n    CONV_DIMS: [-1]\n    HEAD_NAME: StandardRPNHead\n    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n    IOU_LABELS: [0, -1, 1]\n    IOU_THRESHOLDS: [0.3, 0.7]\n    LOSS_WEIGHT: 1.0\n    NMS_THRESH: 0.7\n    POSITIVE_FRACTION: 0.5\n    POST_NMS_TOPK_TEST: 1000\n    POST_NMS_TOPK_TRAIN: 1000\n    PRE_NMS_TOPK_TEST: 1000\n    PRE_NMS_TOPK_TRAIN: 2000\n    SMOOTH_L1_BETA: 0.0\n  SEM_SEG_HEAD:\n    COMMON_STRIDE: 4\n    CONVS_DIM: 128\n    IGNORE_VALUE: 255\n    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n    LOSS_WEIGHT: 1.0\n    NAME: SemSegFPNHead\n    NORM: GN\n    NUM_CLASSES: 54\n  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\nOUTPUT_DIR: ./output\nSEED: -1\nSOLVER:\n  AMP:\n    ENABLED: False\n  BASE_LR: 0.02\n  BIAS_LR_FACTOR: 1.0\n  CHECKPOINT_PERIOD: 5000\n  CLIP_GRADIENTS:\n    CLIP_TYPE: value\n    CLIP_VALUE: 1.0\n    ENABLED: False\n    NORM_TYPE: 2.0\n  GAMMA: 0.1\n  IMS_PER_BATCH: 16\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\n  MAX_ITER: 270000\n  MOMENTUM: 0.9\n  NESTEROV: False\n  REFERENCE_WORLD_SIZE: 0\n  STEPS: (210000, 250000)\n  WARMUP_FACTOR: 0.001\n  WARMUP_ITERS: 1000\n  WARMUP_METHOD: linear\n  WEIGHT_DECAY: 0.0001\n  WEIGHT_DECAY_BIAS: 0.0001\n  WEIGHT_DECAY_NORM: 0.0\nTEST:\n  AUG:\n    ENABLED: False\n    FLIP: True\n    MAX_SIZE: 4000\n    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n  DETECTIONS_PER_IMAGE: 100\n  EVAL_PERIOD: 0\n  EXPECTED_RESULTS: []\n  KEYPOINT_OKS_SIGMAS: []\n  PRECISE_BN:\n    ENABLED: False\n    NUM_ITER: 200\nVERSION: 2\nVIS_PERIOD: 0\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(config)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dump = config.dump()\n",
    "with open(model_path + \"config.yaml\", \"w+\") as output_file:\n",
    "    output_file.write(config_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
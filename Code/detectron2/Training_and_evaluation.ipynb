{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training and evaluation  \n",
    "\n",
    "Das Programm in diesem Notebook dient dem Training und der Auswertung von neuronalen Netzen mit detectron2. Über die einzelnen Codeblöcke werden die nötigen Dateien geladen und das Modell entsprechend konfiguriert."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import load_coco_json, register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_test_loader\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random, cv2, time, os, shutil, ownlabelme2COCO, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "source": [
    "Definition des Hauptpfads, der Input-Pfade und der Output-Pfade"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"/home/julius/PowerFolders/Masterarbeit/\"\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "DATASET_PATH = \"./1_Datensaetze/personData200/\"\n",
    "train_set_path = DATASET_PATH + \"train_split/\"\n",
    "test_set_path = DATASET_PATH + \"test_split/\"\n",
    "\n",
    "starttime = time.strftime(\"%d,%m,%Y-%H,%M\")\n",
    "model_path = \"./trained_models/detectron2/{}/{}/\".format(DATASET_PATH.split(\"/\")[-2], starttime)"
   ]
  },
  {
   "source": [
    "Wichtig für das Training mit detectron2 ist, dass die Daten bereits in die Bereiche \"Training\" und \"Testing\" unterteilt sind und für beide eine entsprechende '.json' Datei im von detectron2 unterstützten COCO Format vorliegt. Sollte dies nicht der Fall sein unterteilt der folgende Codeblock die Bilddaten in ein gegebenens Größenverhältnis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 5\n",
    "\n",
    "if not os.path.isdir(train_set_path) & os.path.isdir(test_set_path):\n",
    "    os.mkdir(train_set_path)\n",
    "    os.mkdir(test_set_path)\n",
    "\n",
    "    images = sorted([element for element in os.listdir(DATASET_PATH) if element.lower().endswith(\".jpg\")])\n",
    "    jsons = sorted([element for element in os.listdir(DATASET_PATH) if element.endswith(\".json\")])\n",
    "\n",
    "    if len(images) != len(jsons):\n",
    "        break\n",
    "\n",
    "    for count in range(len(images)):\n",
    "        if count % SPLIT == 0:\n",
    "            shutil.move(DATASET_PATH + images[count], test_set_path + images[count])\n",
    "            shutil.move(DATASET_PATH + jsons[count], test_set_path + jsons[count])\n",
    "        else:\n",
    "            shutil.move(DATASET_PATH + images[count], train_set_path + images[count])\n",
    "            shutil.move(DATASET_PATH + jsons[count], train_set_path + jsons[count])\n",
    "    \n",
    "    ownlabelme2COCO.main(test_set_path)\n",
    "    ownlabelme2COCO.main(train_set_path)"
   ]
  },
  {
   "source": [
    "Im Anschluss werden der Datensatz für das Training und dast Testing eingelesen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_coco_json(train_set_path + \"COCO_json/output.json\", train_set_path, \"train_set\")\n",
    "register_coco_instances(\"train_set\", {}, train_set_path + \"COCO_json/output.json\", train_set_path)\n",
    "train_set_metadata = MetadataCatalog.get(\"train_set\")\n",
    "train_set_data = DatasetCatalog.get(\"train_set\")\n",
    "\n",
    "load_coco_json(test_set_path + \"COCO_json/output.json\", test_set_path, \"test_set\")\n",
    "register_coco_instances(\"test_set\", {}, test_set_path + \"COCO_json/output.json\", test_set_path)\n",
    "test_set_metadata = MetadataCatalog.get(\"test_set\")\n",
    "test_set_data = DatasetCatalog.get(\"test_set\")"
   ]
  },
  {
   "source": [
    "Zur Kontrolle, ob alle Daten korrekt eingelesen wurden, kann mit dem folgenden Codeblock eine kleine Stichprobe angezeigt werden."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image = random.sample(train_set_data, 1)[0]\n",
    "image = cv2.imread(random_image[\"file_name\"])\n",
    "visualizer = Visualizer(image, metadata=train_set_metadata, scale=1, instance_mode=ColorMode.SEGMENTATION)\n",
    "visualization = visualizer.draw_dataset_dict(random_image)\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.imshow(visualization.get_image()[:,:, ::-1])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "source": [
    "Die hauptsächlichen Stellschrauben für das Training in detectron2 werden über die Wahl der Modellarchitektur und die Konfigurationsdatei eingestellt. Ähnlich wie bei tensorflow basiert die Wahl der einzelnen Faktoren auf Erfahrung und dem Ausprobieren von unterschiedlichen Kombinationen aus Werten."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nconfig.DATASETS.TRAIN = (\"train_set\",)\\nconfig.DATASETS.TEST = (\"test_set\",)\\nconfig.DATALOADER.NUM_WORKERS = 2\\nconfig.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\\nconfig.OUTPUT_DIR = model_path\\nconfig.SOLVER.IMS_PER_BATCH = 2\\nconfig.SOLVER.REFERENCE_WORLD_SIZE = 1\\nconfig.SOLVER.BASE_LR = 0.02\\nconfig.SOLVER.MAX_ITER = 150\\nconfig.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\\nconfig.MODEL.ROI_HEADS.NUM_CLASSES = 16\\nconfig.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "config = get_cfg()\n",
    "config.merge_from_file(\"/home/julius/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "config.DATASETS.TRAIN = (\"train_set\",)\n",
    "config.DATASETS.TEST = (\"test_set\",)\n",
    "#config.DATALOADER.NUM_WORKERS = 2\n",
    "config.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
    "config.OUTPUT_DIR = model_path\n",
    "config.SOLVER.IMS_PER_BATCH = 2\n",
    "config.SOLVER.REFERENCE_WORLD_SIZE = 1\n",
    "config.SOLVER.BASE_LR = 0.02\n",
    "config.SOLVER.MAX_ITER = 300\n",
    "config.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "config.MODEL.RETINANET.NUM_CLASSES = 11\n",
    "config.MODEL.ROI_HEADS.NUM_CLASSES = 11\n",
    "config.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5"
   ]
  },
  {
   "source": [
    "Das eigentliche Training und die Evaluation des Modells wird über die folgenden Codezeilen initialisiert."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainer = DefaultTrainer(config)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "evaluator = COCOEvaluator(\"test_set\", config, distributed=False, output_dir=evaluation_path, use_fast_impl=False)\n",
    "test_loader = build_detection_test_loader(config, \"test_set\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator)"
   ]
  },
  {
   "source": [
    "Zur Dokumentation des Trainings und zur weiteren Verwendung der trainierten Modelle wird abschließend auch die Konfigurationsdatei exportiert.  \n",
    "Es bleibt festzuhalten, dass das hier beschriebene Training nur einen kleinen Umfang besitzt. Die Trainingsergebnisse könnten wie im Umgang mit tensorflow mit Graphen visualisiert werden und die Konfigurationen müssten über verschiedene Trainingsdurchläufe diversifiziert werden. Es war im Rahmen dieser Arbeit nicht möglich vollumfängliche Trainings über große Epochenzahlen auf verschiedenen Datensätzen durchzuführen. Dafür sind die erzielten Ergebnisse vielversprechend und legen nahe, dass eine  weitere Beschäftigung mit der Objekterkennung auf Plakaten lohnenswert sein kann."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dump = config.dump()\n",
    "with open(model_path + \"config.yaml\", \"w+\") as output_file:\n",
    "    output_file.write(config_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
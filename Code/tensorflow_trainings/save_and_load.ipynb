{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bittensorflowvenvc5ae079d33a94b2797c1e2237094a841",
   "display_name": "Python 3.8.5 64-bit ('tensorflow': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# save and load  \n",
    "Quelle: [tensorflow.org](https://www.tensorflow.org/tutorials/keras/save_and_load?hl=en)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.5.0-dev20210218\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 *28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation=\"relu\", input_shape=(784, )),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 512)               401920    \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 7s 20ms/step - loss: 1.5699 - sparse_categorical_accuracy: 0.5318 - val_loss: 0.7176 - val_sparse_categorical_accuracy: 0.7790\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.5147 - val_sparse_categorical_accuracy: 0.8430\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2742 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.4713 - val_sparse_categorical_accuracy: 0.8540\n",
      "\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1760 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8530\n",
      "\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.4235 - val_sparse_categorical_accuracy: 0.8630\n",
      "\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.4197 - val_sparse_categorical_accuracy: 0.8650\n",
      "\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.4207 - val_sparse_categorical_accuracy: 0.8610\n",
      "\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.4295 - val_sparse_categorical_accuracy: 0.8640\n",
      "\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.4234 - val_sparse_categorical_accuracy: 0.8680\n",
      "\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.4071 - val_sparse_categorical_accuracy: 0.8720\n",
      "\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17dde66370>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 - 0s - loss: 2.3930 - sparse_categorical_accuracy: 0.1110\n",
      "Untrained model, accuracy: 11.10%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 - 0s - loss: 0.4071 - sparse_categorical_accuracy: 0.8720\n",
      "Restored model, accuracy: 87.20%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.cpkt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.cpkt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.cpkt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.cpkt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.cpkt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.cpkt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.cpkt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.cpkt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.cpkt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.cpkt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17881acd30>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.cpkt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True, save_freq=5*batch_size)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=50, callbacks=[cp_callback], validation_data=(test_images, test_labels), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "checkpoint                        cp-0025.cpkt.index\ncp-0000.cpkt.data-00000-of-00001  cp-0030.cpkt.data-00000-of-00001\ncp-0000.cpkt.index                cp-0030.cpkt.index\ncp-0005.cpkt.data-00000-of-00001  cp-0035.cpkt.data-00000-of-00001\ncp-0005.cpkt.index                cp-0035.cpkt.index\ncp-0010.cpkt.data-00000-of-00001  cp-0040.cpkt.data-00000-of-00001\ncp-0010.cpkt.index                cp-0040.cpkt.index\ncp-0015.cpkt.data-00000-of-00001  cp-0045.cpkt.data-00000-of-00001\ncp-0015.cpkt.index                cp-0045.cpkt.index\ncp-0020.cpkt.data-00000-of-00001  cp-0050.cpkt.data-00000-of-00001\ncp-0020.cpkt.index                cp-0050.cpkt.index\ncp-0025.cpkt.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'training_2/cp-0050.cpkt'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 - 0s - loss: 0.4920 - sparse_categorical_accuracy: 0.8760\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.load_weights(latest)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 - 0s - loss: 0.4920 - sparse_categorical_accuracy: 0.8760\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"./checkpoints/my_checkpoint\")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.load_weights(\"./checkpoints/my_checkpoint\")\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6216 - sparse_categorical_accuracy: 0.4821\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4269 - sparse_categorical_accuracy: 0.8954\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2709 - sparse_categorical_accuracy: 0.9240\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2250 - sparse_categorical_accuracy: 0.9434\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1577 - sparse_categorical_accuracy: 0.9633\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model.save(\"saved_model/my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0m\u001b[01;34mmy_model\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls saved_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[0m\u001b[01;34massets\u001b[0m/  keras_metadata.pb  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls saved_model/my_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_22 (Dense)             (None, 512)               401920    \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"saved_model/my_model\")\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 - 0s - loss: 0.4328 - sparse_categorical_accuracy: 0.8640\n",
      "Restored model, accuracy: 86.40\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}\".format(100 * acc))\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.6503 - sparse_categorical_accuracy: 0.4907\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4308 - sparse_categorical_accuracy: 0.8776\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3073 - sparse_categorical_accuracy: 0.9244\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1895 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_24 (Dense)             (None, 512)               401920    \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_25 (Dense)             (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"my_model.h5\")\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 - 0s - loss: 0.4198 - sparse_categorical_accuracy: 0.8660\n",
      "restored model, accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}